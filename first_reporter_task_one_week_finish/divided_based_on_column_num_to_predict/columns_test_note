总结：总体的误差和单个的误差相差2，也就是说，这些特征都没有很大程度上能提升性能的特征；
：对于price这个特征：能很大程度上提升预测数据的方差：

        # 以下就是用于测试得新得特征；
        # 'style', #22.769283885157083
        # 'community', # 类似于city类型得数据，类型有766个； #22.38147912725983
        # 'airConditioning', #22.755048806968883
        # 'washrooms', # 连续 #23.691205780782205
        # 'basement1',# 地下室22.797430800725444
        # 'familyRoom', # 22.794731300998404
        # 'fireplaceStove', # 2 w 左右 #22.82878318024665
        # 'heatSource', # 数据量可以2w+# 22.75554140962404
        # 'garageType', # 2 w+ #22.79707321027956
        # 'kitchens', # 22.79393809434976
        # 'parkingSpaces', #22.807931672409705

        # 'parkingIncluded',#22.786586056260784
        # 'rooms',# 22.785397232054713
        #
        # 'waterIncluded', # 22.80653144493355
        # 'totalParkingSpaces', # 22.81551411353129
]]

利用都是22的作为特征，观察误差的变化情况：
22.358400489812382
22.30068348249894s

结果变化都不大；



目前出现一种情况：用特征一个个的去测试，能够得到一定的结果，
但是联合起来之后是不是能导致由于数据量过小，但是特征过多导致的过拟合问题，（而且，方差确实过低）但是
对于以树为基学习器的xgboost有一定的抗过拟合能力，增加特征不能改变情况，但是同样增加数据之后也不能提升
效果；这里就存在一定的问题：
    1：对于训练数据和测试数据是否具有代表性；
    2：是否能够得出时间太久的数据已经缺乏代表性了，



这里有一个问题：用特征多的数据，把数据分离开了之后，再用原来的特征进行预测，结果和用多特征的相差不大，
也就说明，这部分数据预测总体本身就是那么多误差，添加特征之后依旧没有变化；



这里可以有一个解决办法，将daysOnMarket的分时间预测之后然后给一个权重值然后相加，这是一个解决办法；



用listingdate分开数据之后加权重观测效果；
加权之后的效果还是太差了；
接下来只能考虑模型的融合了；
使用stacking 的思想；








