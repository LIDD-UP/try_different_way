用month_567_delistingDate的数据进行测试：

未经过处理的结果：

经过只取listingDate在2018年的数据并且训练数据每个城市的数据至少在50个以上，特征未加入城市：30.3
经过只取listingDate在2018年的数据并且训练数据每个城市的数据至少在50个以上，特征加入城市：30.44712701691593
城市这个特征影响与其他特征在一定方面上有冲突；
经过只取listingDate在2018年的数据并且训练数据每个城市的数据至少在100个以上，特征未加入城市：29.5

-------------》》以上对城市数据的测试一定程度上讲，不均衡数据对样本的影响是比较大的，处理了city的不均衡数据误差就下降了3左右；

省份数据在1000以上的：29.456201464962838

buildingTypeId数据在100条以上的：29.42507842081793，有7个类；
选取buildingTypeId数据量大于1000的：29.394750981718758
选取buildingTypeId数据量大于10000的：29.248132589667932

-----》》》对于buildingTypeId和province的选择，结果变化很小，这个可能是特征本身影响不大，还有就是需要和其他特征的配合；

---》》还有一种可能是类别越多的，如果能保证它的样本数，可能结果会更好，也就是说等一下还需要考虑一下postalCode的处理；


ownershipType
ownershipType每一类别取100以上样本时：29.467808904760307 相比于之前又变差了
1000：29.342067703852642
1000+buidingTypeId_10000:29.16685865823484-----------------------》》》
1000+buidingTypeId_1000:29.277612627377984
10000+buildingTypId_10000:29.216372941993793 结果又增加，所以ownershiptype的类别不能过少，过少了反而影响效果；


bedrooms:
100:29.13
1000:29.159294884745893
10000:29.067176825192128:只取了最多样本的1，2，3，4，5这几个数据；
将bedrooms改为了类别型的变量有所提升但是不大，：29.048239672654045


bathroomTotal:
100:+bedrooms_category:29.07
100:+bedrooms_numeric:29.06
按照实际逻辑上讲：bedrooms应该为numeric，但是有波动，以后还需要多测试；
1000：29.038210600287012
10000 ：29.00471982755364


postalCode:
当值为10的时候：数据量太少了，直接排除：虽然值变成了19，但是方差并没有提升；


tradeTypeId ==1;
31.688541254939455

其实这种思想就是stacking的思想；但是这个不是通过程序方面解决的，而是通过数据方面来解决这个问题；


对于反转数据得测试结果；
合并之后得结果：

以上都是在数据类别方面来提高，并不是去除得异常值，
如何找到异常值，异常值得判定：

tomarrow task：
1：完成反转预测得数据结果备份到note里面
2：做一些简单异常值得处理，主要是针对price得异常值处理；按理说bedrooms和bathroomTotal得也需要处理；
3：重复上诉步骤用数据month1to7；

简单异常值得处理方法：用去除法去除特别大得数据；
对于bedrooms和bathroomTotal也是同样得处理方法；由于这类数据一般在inverse data里面，所以，根据实际结果进行；


上诉步骤完成之后，就是需要考虑模型得stacking了























