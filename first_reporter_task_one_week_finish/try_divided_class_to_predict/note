用month_567_delistingDate的数据进行测试：

未经过处理的结果：

经过只取listingDate在2018年的数据并且训练数据每个城市的数据至少在50个以上，特征未加入城市：30.3
经过只取listingDate在2018年的数据并且训练数据每个城市的数据至少在50个以上，特征加入城市：30.44712701691593
城市这个特征影响与其他特征在一定方面上有冲突；
经过只取listingDate在2018年的数据并且训练数据每个城市的数据至少在100个以上，特征未加入城市：29.5

-------------》》以上对城市数据的测试一定程度上讲，不均衡数据对样本的影响是比较大的，处理了city的不均衡数据误差就下降了3左右；

省份数据在1000以上的：29.456201464962838

buildingTypeId数据在100条以上的：29.42507842081793，有7个类；
选取buildingTypeId数据量大于1000的：29.394750981718758
选取buildingTypeId数据量大于10000的：29.248132589667932

-----》》》对于buildingTypeId和province的选择，结果变化很小，这个可能是特征本身影响不大，还有就是需要和其他特征的配合；

---》》还有一种可能是类别越多的，如果能保证它的样本数，可能结果会更好，也就是说等一下还需要考虑一下postalCode的处理；


ownershipType
ownershipType每一类别取100以上样本时：29.467808904760307 相比于之前又变差了
1000：29.342067703852642
1000+buidingTypeId_10000:29.16685865823484-----------------------》》》
1000+buidingTypeId_1000:29.277612627377984
10000+buildingTypId_10000:29.216372941993793 结果又增加，所以ownershiptype的类别不能过少，过少了反而影响效果；


bedrooms:
100:29.13
1000:29.159294884745893
10000:29.067176825192128:只取了最多样本的1，2，3，4，5这几个数据；
将bedrooms改为了类别型的变量有所提升但是不大，：29.048239672654045


bathroomTotal:
100:+bedrooms_category:29.07
100:+bedrooms_numeric:29.06
按照实际逻辑上讲：bedrooms应该为numeric，但是有波动，以后还需要多测试；
1000：29.038210600287012
10000 ：29.00471982755364


postalCode:
当值为10的时候：数据量太少了，直接排除：虽然值变成了19，但是方差并没有提升；


tradeTypeId ==1;
31.688541254939455

其实这种思想就是stacking的思想；但是这个不是通过程序方面解决的，而是通过数据方面来解决这个问题；


对于反转数据得测试结果；
合并之后得结果：

以上都是在数据类别方面来提高，并不是去除得异常值，
如何找到异常值，异常值得判定：

tomarrow task：
1：完成反转预测得数据结果备份到note里面
2：做一些简单异常值得处理，主要是针对price得异常值处理；按理说bedrooms和bathroomTotal得也需要处理；
3：重复上诉步骤用数据month1to7；

简单异常值得处理方法：用去除法去除特别大得数据；
对于bedrooms和bathroomTotal也是同样得处理方法；由于这类数据一般在inverse data里面，所以，根据实际结果进行；


上诉步骤完成之后，就是需要考虑模型得stacking了


18/9/26
如果按照第一次的处理步骤进行，处理后结果固然结果变小了，但是那是数据量变化导致的，所以应该一定程度只处理city；
结果都是40；但是前后两次inverse的值分别是63 和75；
现在有一个可行的处理方式就是
但是通过listingdate来区分数据并不具有代表性，所以listingdate这个数据并不具备代表性；可能的分类进行预测只能从城市，省份考虑了；

当城市为100的时候总的预测结果还是40；

得出结论：按照不同类别的样本数来进行分模型结果并不会提升；基本保持不变；


现在用分省份城市的方式来进行预测，解决样本类别不均衡的问题；(可能有一定的效果，但是从另一个角度讲是在进行降维，）

从分开类别数据进行训练和预测，结果几乎不变，可以得出无法分开类别进行训练预测，这样没有效果；

看来还是要在异常值方面入手了；

饶了半天还是要回到数据清洗方面：


最后一次ouliers处理：

数据未处理之前：
    40.8204868156204

    处理了price:40.87894803133607

    变高了；
    处理了price和daysOnMarket
    40.830739486918525


    bedrooms<15&&bathroomTotal<1000:40.822005752825525

    bathroomTotal<1000也就是去除了bathroomTotal极度异常的值之后确实有所提升；40.79

    bathrooms<15:40.83043225302004

    利用分析号的特征重要性：来进行测试，
    去掉buildingTyId重要性为0的；40.81

    去掉省份特征为0的小部分数据：

    效果并没有号的提升；

按照leader的做法：把多伦多的分出来进行预测，其余的用总数据训练预测：
其实也是一样的：最终结果也是不变的；它本身内部就是那样的；不管是用总体数据预测还是还是单独分开，它都是基于不同类别的数据进行计算的；
也就是说


还有一种是从数据库中读数据特征更多的数据来进行测试，对于有那些特征的弄一个模型，没有那些特征的弄另外一些模型：
现在开始根据业务来读取有用的特征来使用：查看数据drop之后的情况，根据特征的个数来分模型；
































