#=AttributeError: 'list' object has no attribute 'name'

当loss值波动后不下降加上shuffle = True


LSTM 波士顿房价预测：
    crossent = softmax_loss_function(labels=target, logits=logit)
TypeError: ms_error() got an unexpected keyword argument 'labels'
官网查看，需要将我们传入的函数参数要是命名参数；
softmax_loss_function：函数（标签，logits） - >使用损失批处理而不是标准softmax（默认情况下，如果这是None）。
请注意，为避免混淆，函数需要接受命名参数。

AttributeError: module 'tensorflow' has no attribute 'scalar_summary'
tf.sub 改为了tf.subtract
tf.nn.seq2seq.sequence_loss_by_example 改为了tf.contrib.legacy_seq2seq.sequence_loss_by_example
此处再用pycharm的时候你先查看源代码看不了那是它做了限制，让你无法查看源代码；这时候需要查看官方文档；

tf.train.SummaryWriter改为：tf.summary.FileWriter

tf.merge_all_summaries()改为：summary_op = tf.summary.merge_all

tf.histogram_summary(var.op.name, var)改为：  tf.summary.histogram

KeyError: "The name 'input/xs' refers to an Operation not in the graph."
在有 with tf.name_scope('inputs'): 下的placehold 定义的名字时需要用到inputs/name
比如：        with tf.name_scope('inputs'):
            self.xs = tf.placeholder(tf.float32, [None, n_steps, input_size], name='xs')  # xs 有三个维度
            self.ys = tf.placeholder(tf.float32, [None, n_steps, output_size], name='ys')  # ys 有三个维度
            这时候如果想要通过graph.get_operation_by_name()


ValueError: Variable in_hidden/weights already exists, disallowed.
Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:
定义了两次，


one_hot 编码 sklearn 和 pandas 都有one_hot 独热编码方式：
但是推荐使用pandas 下的get_dummies

把列全部显示出来需要设置
pd.set_option('max_column',100) 就可一了；

用 pandas的getdummies result memeryError 这个可以通过把降入sparse=True 或者时将特征一个个的进行处理；

UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, input_dim=6, kernel_regularizer=<keras.reg...)`
  model.add(Dense(1,input_dim=train.shape[1],W_regularizer=l1(0.001)))
  ：也就是把W_regularizer改为kernel_regularizer

TypeError: Singleton array array(StandardScaler(copy=True, with_mean=True, with_std=True),
      dtype=object) cannot be considered a valid collection.
      :这是由于在训练期间应该使用fit_transform 不应该使用fit，fit和train有点类似但是不太相同；fit相当于是适合得意思；


GridSearchCV和RandomizedSearchCV得区别是一个是暴力组合参数，选择最好得一个是给定一个范围选择最好得；


已经用到得数据处理技术：
    1：数据转换：log变化法
    2：boxplot箱图离群点处理
    3：scatter坐标点数据处理；
    4：标准化
    5：归一化
    6：网格搜索：gridSearchCV
    7：get_dummies(one_hot 编码）
    8:label_encoding(标签编码）
    9：